{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ../transcribe.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile \"../transcribe.py\"\n",
    "#!/usr/bin/env python\n",
    "import colabexts\n",
    "from colabexts import jcommon\n",
    "import whisper,  os, datetime, argparse, io, soundfile, sys, hashlib, torch\n",
    "import numpy as np\n",
    "\n",
    "#-----------------------------models-----------------------------------------------------------------\n",
    "import platform\n",
    "device = \"cpu\"\n",
    "if (torch.cuda.is_available() ):\n",
    "    device = \"cuda\"\n",
    "#elif torch.backends.mps.is_available() and platform.processor() =='arm':\n",
    "#    device = \"mps\"\n",
    "#-----------------------------------------------------------------------------------\n",
    "def transcribe(file =\"/Users/snarayan/Desktop/data/audio/index.mp4\", **kwargs):\n",
    "    tr = whisper.load_model(\"base\", device=device)\n",
    "    result = tr.transcribe(file)\n",
    "    return result\n",
    "#-----------------------------------------------------------------------------------\n",
    "def convert_seconds_to_dhms(total_seconds):\n",
    "    secs = int(total_seconds)\n",
    "    if ( secs <=60):\n",
    "        return str(secs)\n",
    "    seconds = secs % 60\n",
    "    total_minutes = secs // 60\n",
    "    minutes = total_minutes % 60\n",
    "    if ( secs < 3600):\n",
    "        return f\"{minutes}.{seconds}\"\n",
    "\n",
    "    total_hours = total_minutes // 60\n",
    "    hours = total_hours % 24\n",
    "    return f\"{hours}:{minutes}:{seconds}\"\n",
    "#-----------------------------------------------------------------------------------\n",
    "def para(ret):\n",
    "    trans = \"\"\n",
    "    temp = \"\"\n",
    "    for t in ret['segments']:\n",
    "        if (not temp):\n",
    "            ts = convert_seconds_to_dhms(t['start'])\n",
    "            #te = convert_seconds_to_dhms(t['end'])\n",
    "            #temp=f\"{ts} - {te} \"\n",
    "            temp=f\"<a class=timea onclick='vtubegoto({t['start']})' > {ts}: </a>\"\n",
    "        temp += t['text']\n",
    "        if ( len(temp) > 512):\n",
    "            trans += temp + \"\\n\\n\"\n",
    "            temp = \"\"\n",
    "    trans += temp\n",
    "    return (trans)\n",
    "#-----------------------------------------------------------------------------------\n",
    "sysargs=None\n",
    "def addargs():\n",
    "    global sysargs\n",
    "    p = argparse.ArgumentParser(f\"{os.path.basename(sys.argv[0])}:\")\n",
    "    p.add_argument('-u', '--url', type=str, required=1, help=\"File, URL, Youtube URL\")\n",
    "    try:\n",
    "        sysargs, unknown=p.parse_known_args(sys.argv[1:])\n",
    "    except argparse.ArgumentError as exc:\n",
    "        print(exc.message )\n",
    "        \n",
    "    if (unknown):\n",
    "        print(\"Unknown options: \", unknown)\n",
    "    return sysargs\n",
    "#-----------------------------------------------------------------------------------\n",
    "if __name__ == '__main__':\n",
    "    if (not colabexts.jcommon.inJupyter()):\n",
    "        t1 = datetime.datetime.now()\n",
    "        sysargs = addargs()\n",
    "        ret = transcribe(sysargs.url)\n",
    "        par = para(ret)\n",
    "\n",
    "        with open(sysargs.url + \".transcript\", \"w\") as f:\n",
    "            f.write(par)\n",
    "        t2 = datetime.datetime.now()\n",
    "        print(f\"#All Done in {str(t2-t1)} ***\")\n",
    "    else:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 :  Welcome to this fifth course on deep learning. In this course, you learn about sequence models, one of the most exciting areas in deep learning. Models like recurrent neural networks or RNNs have transformed speech recognition, national language processing, and other areas. And in this course, you learn how to build these models for yourself. Let's start by looking at a few examples of what sequence models can be useful. In speech recognition, you are given an input audio clip, X, and R-stimap it to a text-short strip.\n",
      "\n",
      "30 :  Y. Both the input and the output here are sequence data, because X is an audio clip, so that plays out over time. And Y, the output, is a sequence of words. So sequence models, such as recurrent neural networks and other variations, you learn about a little bit, have been very useful for speech recognition. Music generation is another example of a problem with sequence data. In this case, only the output Y is a sequence. The input can be the empty set, or it can be a single integer, maybe referring to the genre of music you want to generate,\n",
      "\n",
      "1.5 :  or maybe the first few notes of the piece of music you want. But here, X can be nothing, or maybe just an integer, and the output Y is a sequence. In sentiment classification, the input X is a sequence. So given the input phrase, like, there's nothing to like in this movie, how many stars do you think this review would be? Sequence models are also very useful for DNA sequence analysis. So your DNA is represented via the four alphabets ACG and T. And so given a DNA sequence, can you label which part of this DNA sequence\n",
      "\n",
      "1.41 :  say corresponds to a protein? In machine translation, you are given an input sentence, the levution of a quaw, and you're asked to output the translation in a different language. In video activity recognition, you might be given a sequence of video frames and asked to recognize the activity. And in named entity recognition, you might be given a sentence and asked to identify the people in that sentence. So all of these problems can be addressed as supervised learning with label data X, comma Y as the training set.\n",
      "\n",
      "2.18 :  But as you can tell from this list of examples, there are a lot of different types of sequence problems. In some, both the input X and the output Y are sequences. And in that case, sometimes X and Y can have different lengths. Or in this example and this example, X and Y have the same length. And in some of these examples, only either X or only the output Y is a sequence. So in this course, you learn about sequence models that are applicable to all of these different settings. So I hope this gives you a sense of the exciting set of problems\n",
      "\n",
      "2.50 :  that sequence models might be that helps you to address. With that, let's go on to the next video, where we start to define the notation we're used to define these sequence problems.\n"
     ]
    }
   ],
   "source": [
    "if not os.environ.get('PATH').__contains__(\"/opt/homebrew/bin\"):\n",
    "    os.environ['PATH'] = os.environ.get('PATH') +':/opt/homebrew/bin'\n",
    "file= \"/Users/e346104/git/DS/vtube/static/vtube/videos/media/index.mp4\"\n",
    "ret = transcribe(file)\n",
    "par = para(ret)\n",
    "print(par)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 - 2  Welcome to this fifth course on deep learning. In this course, you learn about sequence models, one of the most exciting areas in deep learning. Models like recurrent neural networks or RNNs have transformed speech recognition, national language processing, and other areas. And in this course, you learn how to build these models for yourself. Let's start by looking at a few examples of what sequence models can be useful. In speech recognition, you are given an input audio clip, X, and R-stimap it to a text-short strip.\n",
      "\n",
      "30 - 34  Y. Both the input and the output here are sequence data, because X is an audio clip, so that plays out over time. And Y, the output, is a sequence of words. So sequence models, such as recurrent neural networks and other variations, you learn about a little bit, have been very useful for speech recognition. Music generation is another example of a problem with sequence data. In this case, only the output Y is a sequence. The input can be the empty set, or it can be a single integer, maybe referring to the genre of music you want to generate,\n",
      "\n",
      "1.5 - 1.8  or maybe the first few notes of the piece of music you want. But here, X can be nothing, or maybe just an integer, and the output Y is a sequence. In sentiment classification, the input X is a sequence. So given the input phrase, like, there's nothing to like in this movie, how many stars do you think this review would be? Sequence models are also very useful for DNA sequence analysis. So your DNA is represented via the four alphabets ACG and T. And so given a DNA sequence, can you label which part of this DNA sequence\n",
      "\n",
      "1.41 - 1.43  say corresponds to a protein? In machine translation, you are given an input sentence, the levution of a quaw, and you're asked to output the translation in a different language. In video activity recognition, you might be given a sequence of video frames and asked to recognize the activity. And in named entity recognition, you might be given a sentence and asked to identify the people in that sentence. So all of these problems can be addressed as supervised learning with label data X, comma Y as the training set.\n",
      "\n",
      "2.18 - 2.19  But as you can tell from this list of examples, there are a lot of different types of sequence problems. In some, both the input X and the output Y are sequences. And in that case, sometimes X and Y can have different lengths. Or in this example and this example, X and Y have the same length. And in some of these examples, only either X or only the output Y is a sequence. So in this course, you learn about sequence models that are applicable to all of these different settings. So I hope this gives you a sense of the exciting set of problems\n",
      "\n",
      "2.50 - 2.53  that sequence models might be that helps you to address. With that, let's go on to the next video, where we start to define the notation we're used to define these sequence problems.\n"
     ]
    }
   ],
   "source": [
    "par = para(ret)\n",
    "print(par)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 ==> 0\n",
      "10 ==> 10\n",
      "59 ==> 59\n",
      "60 ==> 60\n",
      "62 ==> 1.2\n",
      "360 ==> 6.0\n",
      "3600 ==> 1:0:0\n",
      "3800 ==> 1:3:20\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "tsts = [0, 10, 59, 60, 62, 360, 3600, 3800]\n",
    "for t in tsts:\n",
    "    print(t, \"==>\", convert_seconds_to_dhms(t)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f\"{start} {end}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': \" Welcome to this fifth course on deep learning. In this course, you learn about sequence models, one of the most exciting areas in deep learning. Models like recurrent neural networks or RNNs have transformed speech recognition, national language processing, and other areas. And in this course, you learn how to build these models for yourself. Let's start by looking at a few examples of what sequence models can be useful. In speech recognition, you are given an input audio clip, X, and R-stimap it to a text-short strip. Y. Both the input and the output here are sequence data, because X is an audio clip, so that plays out over time. And Y, the output, is a sequence of words. So sequence models, such as recurrent neural networks and other variations, you learn about a little bit, have been very useful for speech recognition. Music generation is another example of a problem with sequence data. In this case, only the output Y is a sequence. The input can be the empty set, or it can be a single integer, maybe referring to the genre of music you want to generate, or maybe the first few notes of the piece of music you want. But here, X can be nothing, or maybe just an integer, and the output Y is a sequence. In sentiment classification, the input X is a sequence. So given the input phrase, like, there's nothing to like in this movie, how many stars do you think this review would be? Sequence models are also very useful for DNA sequence analysis. So your DNA is represented via the four alphabets ACG and T. And so given a DNA sequence, can you label which part of this DNA sequence say corresponds to a protein? In machine translation, you are given an input sentence, the levution of a quaw, and you're asked to output the translation in a different language. In video activity recognition, you might be given a sequence of video frames and asked to recognize the activity. And in named entity recognition, you might be given a sentence and asked to identify the people in that sentence. So all of these problems can be addressed as supervised learning with label data X, comma Y as the training set. But as you can tell from this list of examples, there are a lot of different types of sequence problems. In some, both the input X and the output Y are sequences. And in that case, sometimes X and Y can have different lengths. Or in this example and this example, X and Y have the same length. And in some of these examples, only either X or only the output Y is a sequence. So in this course, you learn about sequence models that are applicable to all of these different settings. So I hope this gives you a sense of the exciting set of problems that sequence models might be that helps you to address. With that, let's go on to the next video, where we start to define the notation we're used to define these sequence problems.\",\n",
       " 'segments': [{'id': 0,\n",
       "   'seek': 0,\n",
       "   'start': 0.0,\n",
       "   'end': 2.8000000000000003,\n",
       "   'text': ' Welcome to this fifth course on deep learning.',\n",
       "   'tokens': [50364, 4027, 281, 341, 9266, 1164, 322, 2452, 2539, 13, 50504],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.2007595942570613,\n",
       "   'compression_ratio': 1.7655677655677655,\n",
       "   'no_speech_prob': 0.014252539724111557},\n",
       "  {'id': 1,\n",
       "   'seek': 0,\n",
       "   'start': 2.8000000000000003,\n",
       "   'end': 5.36,\n",
       "   'text': ' In this course, you learn about sequence models,',\n",
       "   'tokens': [50504,\n",
       "    682,\n",
       "    341,\n",
       "    1164,\n",
       "    11,\n",
       "    291,\n",
       "    1466,\n",
       "    466,\n",
       "    8310,\n",
       "    5245,\n",
       "    11,\n",
       "    50632],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.2007595942570613,\n",
       "   'compression_ratio': 1.7655677655677655,\n",
       "   'no_speech_prob': 0.014252539724111557},\n",
       "  {'id': 2,\n",
       "   'seek': 0,\n",
       "   'start': 5.36,\n",
       "   'end': 7.8,\n",
       "   'text': ' one of the most exciting areas in deep learning.',\n",
       "   'tokens': [50632,\n",
       "    472,\n",
       "    295,\n",
       "    264,\n",
       "    881,\n",
       "    4670,\n",
       "    3179,\n",
       "    294,\n",
       "    2452,\n",
       "    2539,\n",
       "    13,\n",
       "    50754],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.2007595942570613,\n",
       "   'compression_ratio': 1.7655677655677655,\n",
       "   'no_speech_prob': 0.014252539724111557},\n",
       "  {'id': 3,\n",
       "   'seek': 0,\n",
       "   'start': 7.8,\n",
       "   'end': 10.96,\n",
       "   'text': ' Models like recurrent neural networks or RNNs',\n",
       "   'tokens': [50754,\n",
       "    6583,\n",
       "    1625,\n",
       "    411,\n",
       "    18680,\n",
       "    1753,\n",
       "    18161,\n",
       "    9590,\n",
       "    420,\n",
       "    45702,\n",
       "    45,\n",
       "    82,\n",
       "    50912],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.2007595942570613,\n",
       "   'compression_ratio': 1.7655677655677655,\n",
       "   'no_speech_prob': 0.014252539724111557},\n",
       "  {'id': 4,\n",
       "   'seek': 0,\n",
       "   'start': 10.96,\n",
       "   'end': 13.040000000000001,\n",
       "   'text': ' have transformed speech recognition,',\n",
       "   'tokens': [50912, 362, 16894, 6218, 11150, 11, 51016],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.2007595942570613,\n",
       "   'compression_ratio': 1.7655677655677655,\n",
       "   'no_speech_prob': 0.014252539724111557},\n",
       "  {'id': 5,\n",
       "   'seek': 0,\n",
       "   'start': 13.040000000000001,\n",
       "   'end': 15.56,\n",
       "   'text': ' national language processing, and other areas.',\n",
       "   'tokens': [51016, 4048, 2856, 9007, 11, 293, 661, 3179, 13, 51142],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.2007595942570613,\n",
       "   'compression_ratio': 1.7655677655677655,\n",
       "   'no_speech_prob': 0.014252539724111557},\n",
       "  {'id': 6,\n",
       "   'seek': 0,\n",
       "   'start': 15.56,\n",
       "   'end': 18.88,\n",
       "   'text': ' And in this course, you learn how to build these models for yourself.',\n",
       "   'tokens': [51142,\n",
       "    400,\n",
       "    294,\n",
       "    341,\n",
       "    1164,\n",
       "    11,\n",
       "    291,\n",
       "    1466,\n",
       "    577,\n",
       "    281,\n",
       "    1322,\n",
       "    613,\n",
       "    5245,\n",
       "    337,\n",
       "    1803,\n",
       "    13,\n",
       "    51308],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.2007595942570613,\n",
       "   'compression_ratio': 1.7655677655677655,\n",
       "   'no_speech_prob': 0.014252539724111557},\n",
       "  {'id': 7,\n",
       "   'seek': 0,\n",
       "   'start': 18.88,\n",
       "   'end': 22.8,\n",
       "   'text': \" Let's start by looking at a few examples of what sequence models can be useful.\",\n",
       "   'tokens': [51308,\n",
       "    961,\n",
       "    311,\n",
       "    722,\n",
       "    538,\n",
       "    1237,\n",
       "    412,\n",
       "    257,\n",
       "    1326,\n",
       "    5110,\n",
       "    295,\n",
       "    437,\n",
       "    8310,\n",
       "    5245,\n",
       "    393,\n",
       "    312,\n",
       "    4420,\n",
       "    13,\n",
       "    51504],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.2007595942570613,\n",
       "   'compression_ratio': 1.7655677655677655,\n",
       "   'no_speech_prob': 0.014252539724111557},\n",
       "  {'id': 8,\n",
       "   'seek': 0,\n",
       "   'start': 22.8,\n",
       "   'end': 26.96,\n",
       "   'text': ' In speech recognition, you are given an input audio clip,',\n",
       "   'tokens': [51504,\n",
       "    682,\n",
       "    6218,\n",
       "    11150,\n",
       "    11,\n",
       "    291,\n",
       "    366,\n",
       "    2212,\n",
       "    364,\n",
       "    4846,\n",
       "    6278,\n",
       "    7353,\n",
       "    11,\n",
       "    51712],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.2007595942570613,\n",
       "   'compression_ratio': 1.7655677655677655,\n",
       "   'no_speech_prob': 0.014252539724111557},\n",
       "  {'id': 9,\n",
       "   'seek': 2696,\n",
       "   'start': 26.96,\n",
       "   'end': 30.880000000000003,\n",
       "   'text': ' X, and R-stimap it to a text-short strip.',\n",
       "   'tokens': [50364,\n",
       "    1783,\n",
       "    11,\n",
       "    293,\n",
       "    497,\n",
       "    12,\n",
       "    372,\n",
       "    332,\n",
       "    569,\n",
       "    309,\n",
       "    281,\n",
       "    257,\n",
       "    2487,\n",
       "    12,\n",
       "    2716,\n",
       "    477,\n",
       "    12828,\n",
       "    13,\n",
       "    50560],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.258565750797238,\n",
       "   'compression_ratio': 1.624031007751938,\n",
       "   'no_speech_prob': 0.0010247755562886596},\n",
       "  {'id': 10,\n",
       "   'seek': 2696,\n",
       "   'start': 30.880000000000003,\n",
       "   'end': 34.480000000000004,\n",
       "   'text': ' Y. Both the input and the output here are sequence data,',\n",
       "   'tokens': [50560,\n",
       "    398,\n",
       "    13,\n",
       "    6767,\n",
       "    264,\n",
       "    4846,\n",
       "    293,\n",
       "    264,\n",
       "    5598,\n",
       "    510,\n",
       "    366,\n",
       "    8310,\n",
       "    1412,\n",
       "    11,\n",
       "    50740],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.258565750797238,\n",
       "   'compression_ratio': 1.624031007751938,\n",
       "   'no_speech_prob': 0.0010247755562886596},\n",
       "  {'id': 11,\n",
       "   'seek': 2696,\n",
       "   'start': 34.480000000000004,\n",
       "   'end': 37.92,\n",
       "   'text': ' because X is an audio clip, so that plays out over time.',\n",
       "   'tokens': [50740,\n",
       "    570,\n",
       "    1783,\n",
       "    307,\n",
       "    364,\n",
       "    6278,\n",
       "    7353,\n",
       "    11,\n",
       "    370,\n",
       "    300,\n",
       "    5749,\n",
       "    484,\n",
       "    670,\n",
       "    565,\n",
       "    13,\n",
       "    50912],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.258565750797238,\n",
       "   'compression_ratio': 1.624031007751938,\n",
       "   'no_speech_prob': 0.0010247755562886596},\n",
       "  {'id': 12,\n",
       "   'seek': 2696,\n",
       "   'start': 37.92,\n",
       "   'end': 41.2,\n",
       "   'text': ' And Y, the output, is a sequence of words.',\n",
       "   'tokens': [50912,\n",
       "    400,\n",
       "    398,\n",
       "    11,\n",
       "    264,\n",
       "    5598,\n",
       "    11,\n",
       "    307,\n",
       "    257,\n",
       "    8310,\n",
       "    295,\n",
       "    2283,\n",
       "    13,\n",
       "    51076],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.258565750797238,\n",
       "   'compression_ratio': 1.624031007751938,\n",
       "   'no_speech_prob': 0.0010247755562886596},\n",
       "  {'id': 13,\n",
       "   'seek': 2696,\n",
       "   'start': 41.2,\n",
       "   'end': 44.96,\n",
       "   'text': ' So sequence models, such as recurrent neural networks and other variations,',\n",
       "   'tokens': [51076,\n",
       "    407,\n",
       "    8310,\n",
       "    5245,\n",
       "    11,\n",
       "    1270,\n",
       "    382,\n",
       "    18680,\n",
       "    1753,\n",
       "    18161,\n",
       "    9590,\n",
       "    293,\n",
       "    661,\n",
       "    17840,\n",
       "    11,\n",
       "    51264],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.258565750797238,\n",
       "   'compression_ratio': 1.624031007751938,\n",
       "   'no_speech_prob': 0.0010247755562886596},\n",
       "  {'id': 14,\n",
       "   'seek': 2696,\n",
       "   'start': 44.96,\n",
       "   'end': 48.88,\n",
       "   'text': ' you learn about a little bit, have been very useful for speech recognition.',\n",
       "   'tokens': [51264,\n",
       "    291,\n",
       "    1466,\n",
       "    466,\n",
       "    257,\n",
       "    707,\n",
       "    857,\n",
       "    11,\n",
       "    362,\n",
       "    668,\n",
       "    588,\n",
       "    4420,\n",
       "    337,\n",
       "    6218,\n",
       "    11150,\n",
       "    13,\n",
       "    51460],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.258565750797238,\n",
       "   'compression_ratio': 1.624031007751938,\n",
       "   'no_speech_prob': 0.0010247755562886596},\n",
       "  {'id': 15,\n",
       "   'seek': 2696,\n",
       "   'start': 48.88,\n",
       "   'end': 54.08,\n",
       "   'text': ' Music generation is another example of a problem with sequence data.',\n",
       "   'tokens': [51460,\n",
       "    7609,\n",
       "    5125,\n",
       "    307,\n",
       "    1071,\n",
       "    1365,\n",
       "    295,\n",
       "    257,\n",
       "    1154,\n",
       "    365,\n",
       "    8310,\n",
       "    1412,\n",
       "    13,\n",
       "    51720],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.258565750797238,\n",
       "   'compression_ratio': 1.624031007751938,\n",
       "   'no_speech_prob': 0.0010247755562886596},\n",
       "  {'id': 16,\n",
       "   'seek': 5408,\n",
       "   'start': 54.16,\n",
       "   'end': 57.36,\n",
       "   'text': ' In this case, only the output Y is a sequence.',\n",
       "   'tokens': [50368,\n",
       "    682,\n",
       "    341,\n",
       "    1389,\n",
       "    11,\n",
       "    787,\n",
       "    264,\n",
       "    5598,\n",
       "    398,\n",
       "    307,\n",
       "    257,\n",
       "    8310,\n",
       "    13,\n",
       "    50528],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.1361911961289703,\n",
       "   'compression_ratio': 1.8893617021276596,\n",
       "   'no_speech_prob': 0.0018950882367789745},\n",
       "  {'id': 17,\n",
       "   'seek': 5408,\n",
       "   'start': 57.36,\n",
       "   'end': 62.56,\n",
       "   'text': ' The input can be the empty set, or it can be a single integer,',\n",
       "   'tokens': [50528,\n",
       "    440,\n",
       "    4846,\n",
       "    393,\n",
       "    312,\n",
       "    264,\n",
       "    6707,\n",
       "    992,\n",
       "    11,\n",
       "    420,\n",
       "    309,\n",
       "    393,\n",
       "    312,\n",
       "    257,\n",
       "    2167,\n",
       "    24922,\n",
       "    11,\n",
       "    50788],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.1361911961289703,\n",
       "   'compression_ratio': 1.8893617021276596,\n",
       "   'no_speech_prob': 0.0018950882367789745},\n",
       "  {'id': 18,\n",
       "   'seek': 5408,\n",
       "   'start': 62.56,\n",
       "   'end': 65.28,\n",
       "   'text': ' maybe referring to the genre of music you want to generate,',\n",
       "   'tokens': [50788,\n",
       "    1310,\n",
       "    13761,\n",
       "    281,\n",
       "    264,\n",
       "    11022,\n",
       "    295,\n",
       "    1318,\n",
       "    291,\n",
       "    528,\n",
       "    281,\n",
       "    8460,\n",
       "    11,\n",
       "    50924],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.1361911961289703,\n",
       "   'compression_ratio': 1.8893617021276596,\n",
       "   'no_speech_prob': 0.0018950882367789745},\n",
       "  {'id': 19,\n",
       "   'seek': 5408,\n",
       "   'start': 65.28,\n",
       "   'end': 68.08,\n",
       "   'text': ' or maybe the first few notes of the piece of music you want.',\n",
       "   'tokens': [50924,\n",
       "    420,\n",
       "    1310,\n",
       "    264,\n",
       "    700,\n",
       "    1326,\n",
       "    5570,\n",
       "    295,\n",
       "    264,\n",
       "    2522,\n",
       "    295,\n",
       "    1318,\n",
       "    291,\n",
       "    528,\n",
       "    13,\n",
       "    51064],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.1361911961289703,\n",
       "   'compression_ratio': 1.8893617021276596,\n",
       "   'no_speech_prob': 0.0018950882367789745},\n",
       "  {'id': 20,\n",
       "   'seek': 5408,\n",
       "   'start': 68.08,\n",
       "   'end': 73.12,\n",
       "   'text': ' But here, X can be nothing, or maybe just an integer,',\n",
       "   'tokens': [51064,\n",
       "    583,\n",
       "    510,\n",
       "    11,\n",
       "    1783,\n",
       "    393,\n",
       "    312,\n",
       "    1825,\n",
       "    11,\n",
       "    420,\n",
       "    1310,\n",
       "    445,\n",
       "    364,\n",
       "    24922,\n",
       "    11,\n",
       "    51316],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.1361911961289703,\n",
       "   'compression_ratio': 1.8893617021276596,\n",
       "   'no_speech_prob': 0.0018950882367789745},\n",
       "  {'id': 21,\n",
       "   'seek': 5408,\n",
       "   'start': 73.12,\n",
       "   'end': 75.92,\n",
       "   'text': ' and the output Y is a sequence.',\n",
       "   'tokens': [51316, 293, 264, 5598, 398, 307, 257, 8310, 13, 51456],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.1361911961289703,\n",
       "   'compression_ratio': 1.8893617021276596,\n",
       "   'no_speech_prob': 0.0018950882367789745},\n",
       "  {'id': 22,\n",
       "   'seek': 5408,\n",
       "   'start': 75.92,\n",
       "   'end': 79.2,\n",
       "   'text': ' In sentiment classification, the input X is a sequence.',\n",
       "   'tokens': [51456,\n",
       "    682,\n",
       "    16149,\n",
       "    21538,\n",
       "    11,\n",
       "    264,\n",
       "    4846,\n",
       "    1783,\n",
       "    307,\n",
       "    257,\n",
       "    8310,\n",
       "    13,\n",
       "    51620],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.1361911961289703,\n",
       "   'compression_ratio': 1.8893617021276596,\n",
       "   'no_speech_prob': 0.0018950882367789745},\n",
       "  {'id': 23,\n",
       "   'seek': 5408,\n",
       "   'start': 79.2,\n",
       "   'end': 82.96,\n",
       "   'text': \" So given the input phrase, like, there's nothing to like in this movie,\",\n",
       "   'tokens': [51620,\n",
       "    407,\n",
       "    2212,\n",
       "    264,\n",
       "    4846,\n",
       "    9535,\n",
       "    11,\n",
       "    411,\n",
       "    11,\n",
       "    456,\n",
       "    311,\n",
       "    1825,\n",
       "    281,\n",
       "    411,\n",
       "    294,\n",
       "    341,\n",
       "    3169,\n",
       "    11,\n",
       "    51808],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.1361911961289703,\n",
       "   'compression_ratio': 1.8893617021276596,\n",
       "   'no_speech_prob': 0.0018950882367789745},\n",
       "  {'id': 24,\n",
       "   'seek': 8296,\n",
       "   'start': 82.96,\n",
       "   'end': 86.32,\n",
       "   'text': ' how many stars do you think this review would be?',\n",
       "   'tokens': [50364,\n",
       "    577,\n",
       "    867,\n",
       "    6105,\n",
       "    360,\n",
       "    291,\n",
       "    519,\n",
       "    341,\n",
       "    3131,\n",
       "    576,\n",
       "    312,\n",
       "    30,\n",
       "    50532],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.22249886648995534,\n",
       "   'compression_ratio': 1.625,\n",
       "   'no_speech_prob': 0.0011189861688762903},\n",
       "  {'id': 25,\n",
       "   'seek': 8296,\n",
       "   'start': 86.32,\n",
       "   'end': 91.03999999999999,\n",
       "   'text': ' Sequence models are also very useful for DNA sequence analysis.',\n",
       "   'tokens': [50532,\n",
       "    46859,\n",
       "    655,\n",
       "    5245,\n",
       "    366,\n",
       "    611,\n",
       "    588,\n",
       "    4420,\n",
       "    337,\n",
       "    8272,\n",
       "    8310,\n",
       "    5215,\n",
       "    13,\n",
       "    50768],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.22249886648995534,\n",
       "   'compression_ratio': 1.625,\n",
       "   'no_speech_prob': 0.0011189861688762903},\n",
       "  {'id': 26,\n",
       "   'seek': 8296,\n",
       "   'start': 91.03999999999999,\n",
       "   'end': 96.39999999999999,\n",
       "   'text': ' So your DNA is represented via the four alphabets ACG and T.',\n",
       "   'tokens': [50768,\n",
       "    407,\n",
       "    428,\n",
       "    8272,\n",
       "    307,\n",
       "    10379,\n",
       "    5766,\n",
       "    264,\n",
       "    1451,\n",
       "    419,\n",
       "    950,\n",
       "    455,\n",
       "    1385,\n",
       "    8157,\n",
       "    38,\n",
       "    293,\n",
       "    314,\n",
       "    13,\n",
       "    51036],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.22249886648995534,\n",
       "   'compression_ratio': 1.625,\n",
       "   'no_speech_prob': 0.0011189861688762903},\n",
       "  {'id': 27,\n",
       "   'seek': 8296,\n",
       "   'start': 96.39999999999999,\n",
       "   'end': 101.6,\n",
       "   'text': ' And so given a DNA sequence, can you label which part of this DNA sequence',\n",
       "   'tokens': [51036,\n",
       "    400,\n",
       "    370,\n",
       "    2212,\n",
       "    257,\n",
       "    8272,\n",
       "    8310,\n",
       "    11,\n",
       "    393,\n",
       "    291,\n",
       "    7645,\n",
       "    597,\n",
       "    644,\n",
       "    295,\n",
       "    341,\n",
       "    8272,\n",
       "    8310,\n",
       "    51296],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.22249886648995534,\n",
       "   'compression_ratio': 1.625,\n",
       "   'no_speech_prob': 0.0011189861688762903},\n",
       "  {'id': 28,\n",
       "   'seek': 8296,\n",
       "   'start': 101.6,\n",
       "   'end': 103.91999999999999,\n",
       "   'text': ' say corresponds to a protein?',\n",
       "   'tokens': [51296, 584, 23249, 281, 257, 7944, 30, 51412],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.22249886648995534,\n",
       "   'compression_ratio': 1.625,\n",
       "   'no_speech_prob': 0.0011189861688762903},\n",
       "  {'id': 29,\n",
       "   'seek': 8296,\n",
       "   'start': 103.91999999999999,\n",
       "   'end': 107.11999999999999,\n",
       "   'text': ' In machine translation, you are given an input sentence,',\n",
       "   'tokens': [51412,\n",
       "    682,\n",
       "    3479,\n",
       "    12853,\n",
       "    11,\n",
       "    291,\n",
       "    366,\n",
       "    2212,\n",
       "    364,\n",
       "    4846,\n",
       "    8174,\n",
       "    11,\n",
       "    51572],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.22249886648995534,\n",
       "   'compression_ratio': 1.625,\n",
       "   'no_speech_prob': 0.0011189861688762903},\n",
       "  {'id': 30,\n",
       "   'seek': 8296,\n",
       "   'start': 107.11999999999999,\n",
       "   'end': 111.67999999999999,\n",
       "   'text': \" the levution of a quaw, and you're asked to output the translation\",\n",
       "   'tokens': [51572,\n",
       "    264,\n",
       "    20445,\n",
       "    1448,\n",
       "    295,\n",
       "    257,\n",
       "    421,\n",
       "    1607,\n",
       "    11,\n",
       "    293,\n",
       "    291,\n",
       "    434,\n",
       "    2351,\n",
       "    281,\n",
       "    5598,\n",
       "    264,\n",
       "    12853,\n",
       "    51800],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.22249886648995534,\n",
       "   'compression_ratio': 1.625,\n",
       "   'no_speech_prob': 0.0011189861688762903},\n",
       "  {'id': 31,\n",
       "   'seek': 11168,\n",
       "   'start': 111.68,\n",
       "   'end': 113.60000000000001,\n",
       "   'text': ' in a different language.',\n",
       "   'tokens': [50364, 294, 257, 819, 2856, 13, 50460],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.12932855606079102,\n",
       "   'compression_ratio': 1.764957264957265,\n",
       "   'no_speech_prob': 0.0017196082044392824},\n",
       "  {'id': 32,\n",
       "   'seek': 11168,\n",
       "   'start': 113.60000000000001,\n",
       "   'end': 118.4,\n",
       "   'text': ' In video activity recognition, you might be given a sequence of video frames',\n",
       "   'tokens': [50460,\n",
       "    682,\n",
       "    960,\n",
       "    5191,\n",
       "    11150,\n",
       "    11,\n",
       "    291,\n",
       "    1062,\n",
       "    312,\n",
       "    2212,\n",
       "    257,\n",
       "    8310,\n",
       "    295,\n",
       "    960,\n",
       "    12083,\n",
       "    50700],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.12932855606079102,\n",
       "   'compression_ratio': 1.764957264957265,\n",
       "   'no_speech_prob': 0.0017196082044392824},\n",
       "  {'id': 33,\n",
       "   'seek': 11168,\n",
       "   'start': 118.4,\n",
       "   'end': 120.88000000000001,\n",
       "   'text': ' and asked to recognize the activity.',\n",
       "   'tokens': [50700, 293, 2351, 281, 5521, 264, 5191, 13, 50824],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.12932855606079102,\n",
       "   'compression_ratio': 1.764957264957265,\n",
       "   'no_speech_prob': 0.0017196082044392824},\n",
       "  {'id': 34,\n",
       "   'seek': 11168,\n",
       "   'start': 120.88000000000001,\n",
       "   'end': 125.2,\n",
       "   'text': ' And in named entity recognition, you might be given a sentence',\n",
       "   'tokens': [50824,\n",
       "    400,\n",
       "    294,\n",
       "    4926,\n",
       "    13977,\n",
       "    11150,\n",
       "    11,\n",
       "    291,\n",
       "    1062,\n",
       "    312,\n",
       "    2212,\n",
       "    257,\n",
       "    8174,\n",
       "    51040],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.12932855606079102,\n",
       "   'compression_ratio': 1.764957264957265,\n",
       "   'no_speech_prob': 0.0017196082044392824},\n",
       "  {'id': 35,\n",
       "   'seek': 11168,\n",
       "   'start': 125.2,\n",
       "   'end': 128.8,\n",
       "   'text': ' and asked to identify the people in that sentence.',\n",
       "   'tokens': [51040,\n",
       "    293,\n",
       "    2351,\n",
       "    281,\n",
       "    5876,\n",
       "    264,\n",
       "    561,\n",
       "    294,\n",
       "    300,\n",
       "    8174,\n",
       "    13,\n",
       "    51220],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.12932855606079102,\n",
       "   'compression_ratio': 1.764957264957265,\n",
       "   'no_speech_prob': 0.0017196082044392824},\n",
       "  {'id': 36,\n",
       "   'seek': 11168,\n",
       "   'start': 128.8,\n",
       "   'end': 133.04000000000002,\n",
       "   'text': ' So all of these problems can be addressed as supervised learning',\n",
       "   'tokens': [51220,\n",
       "    407,\n",
       "    439,\n",
       "    295,\n",
       "    613,\n",
       "    2740,\n",
       "    393,\n",
       "    312,\n",
       "    13847,\n",
       "    382,\n",
       "    46533,\n",
       "    2539,\n",
       "    51432],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.12932855606079102,\n",
       "   'compression_ratio': 1.764957264957265,\n",
       "   'no_speech_prob': 0.0017196082044392824},\n",
       "  {'id': 37,\n",
       "   'seek': 11168,\n",
       "   'start': 133.04000000000002,\n",
       "   'end': 138.0,\n",
       "   'text': ' with label data X, comma Y as the training set.',\n",
       "   'tokens': [51432,\n",
       "    365,\n",
       "    7645,\n",
       "    1412,\n",
       "    1783,\n",
       "    11,\n",
       "    22117,\n",
       "    398,\n",
       "    382,\n",
       "    264,\n",
       "    3097,\n",
       "    992,\n",
       "    13,\n",
       "    51680],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.12932855606079102,\n",
       "   'compression_ratio': 1.764957264957265,\n",
       "   'no_speech_prob': 0.0017196082044392824},\n",
       "  {'id': 38,\n",
       "   'seek': 11168,\n",
       "   'start': 138.0,\n",
       "   'end': 139.92000000000002,\n",
       "   'text': ' But as you can tell from this list of examples,',\n",
       "   'tokens': [51680,\n",
       "    583,\n",
       "    382,\n",
       "    291,\n",
       "    393,\n",
       "    980,\n",
       "    490,\n",
       "    341,\n",
       "    1329,\n",
       "    295,\n",
       "    5110,\n",
       "    11,\n",
       "    51776],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.12932855606079102,\n",
       "   'compression_ratio': 1.764957264957265,\n",
       "   'no_speech_prob': 0.0017196082044392824},\n",
       "  {'id': 39,\n",
       "   'seek': 13992,\n",
       "   'start': 139.92,\n",
       "   'end': 142.72,\n",
       "   'text': ' there are a lot of different types of sequence problems.',\n",
       "   'tokens': [50364,\n",
       "    456,\n",
       "    366,\n",
       "    257,\n",
       "    688,\n",
       "    295,\n",
       "    819,\n",
       "    3467,\n",
       "    295,\n",
       "    8310,\n",
       "    2740,\n",
       "    13,\n",
       "    50504],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.1197039084001021,\n",
       "   'compression_ratio': 1.8908296943231442,\n",
       "   'no_speech_prob': 0.00260812952183187},\n",
       "  {'id': 40,\n",
       "   'seek': 13992,\n",
       "   'start': 142.72,\n",
       "   'end': 146.79999999999998,\n",
       "   'text': ' In some, both the input X and the output Y are sequences.',\n",
       "   'tokens': [50504,\n",
       "    682,\n",
       "    512,\n",
       "    11,\n",
       "    1293,\n",
       "    264,\n",
       "    4846,\n",
       "    1783,\n",
       "    293,\n",
       "    264,\n",
       "    5598,\n",
       "    398,\n",
       "    366,\n",
       "    22978,\n",
       "    13,\n",
       "    50708],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.1197039084001021,\n",
       "   'compression_ratio': 1.8908296943231442,\n",
       "   'no_speech_prob': 0.00260812952183187},\n",
       "  {'id': 41,\n",
       "   'seek': 13992,\n",
       "   'start': 146.79999999999998,\n",
       "   'end': 150.72,\n",
       "   'text': ' And in that case, sometimes X and Y can have different lengths.',\n",
       "   'tokens': [50708,\n",
       "    400,\n",
       "    294,\n",
       "    300,\n",
       "    1389,\n",
       "    11,\n",
       "    2171,\n",
       "    1783,\n",
       "    293,\n",
       "    398,\n",
       "    393,\n",
       "    362,\n",
       "    819,\n",
       "    26329,\n",
       "    13,\n",
       "    50904],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.1197039084001021,\n",
       "   'compression_ratio': 1.8908296943231442,\n",
       "   'no_speech_prob': 0.00260812952183187},\n",
       "  {'id': 42,\n",
       "   'seek': 13992,\n",
       "   'start': 150.72,\n",
       "   'end': 155.44,\n",
       "   'text': ' Or in this example and this example, X and Y have the same length.',\n",
       "   'tokens': [50904,\n",
       "    1610,\n",
       "    294,\n",
       "    341,\n",
       "    1365,\n",
       "    293,\n",
       "    341,\n",
       "    1365,\n",
       "    11,\n",
       "    1783,\n",
       "    293,\n",
       "    398,\n",
       "    362,\n",
       "    264,\n",
       "    912,\n",
       "    4641,\n",
       "    13,\n",
       "    51140],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.1197039084001021,\n",
       "   'compression_ratio': 1.8908296943231442,\n",
       "   'no_speech_prob': 0.00260812952183187},\n",
       "  {'id': 43,\n",
       "   'seek': 13992,\n",
       "   'start': 155.44,\n",
       "   'end': 160.95999999999998,\n",
       "   'text': ' And in some of these examples, only either X or only the output Y is a sequence.',\n",
       "   'tokens': [51140,\n",
       "    400,\n",
       "    294,\n",
       "    512,\n",
       "    295,\n",
       "    613,\n",
       "    5110,\n",
       "    11,\n",
       "    787,\n",
       "    2139,\n",
       "    1783,\n",
       "    420,\n",
       "    787,\n",
       "    264,\n",
       "    5598,\n",
       "    398,\n",
       "    307,\n",
       "    257,\n",
       "    8310,\n",
       "    13,\n",
       "    51416],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.1197039084001021,\n",
       "   'compression_ratio': 1.8908296943231442,\n",
       "   'no_speech_prob': 0.00260812952183187},\n",
       "  {'id': 44,\n",
       "   'seek': 13992,\n",
       "   'start': 160.95999999999998,\n",
       "   'end': 164.0,\n",
       "   'text': ' So in this course, you learn about sequence models that are applicable',\n",
       "   'tokens': [51416,\n",
       "    407,\n",
       "    294,\n",
       "    341,\n",
       "    1164,\n",
       "    11,\n",
       "    291,\n",
       "    1466,\n",
       "    466,\n",
       "    8310,\n",
       "    5245,\n",
       "    300,\n",
       "    366,\n",
       "    21142,\n",
       "    51568],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.1197039084001021,\n",
       "   'compression_ratio': 1.8908296943231442,\n",
       "   'no_speech_prob': 0.00260812952183187},\n",
       "  {'id': 45,\n",
       "   'seek': 13992,\n",
       "   'start': 164.0,\n",
       "   'end': 166.39999999999998,\n",
       "   'text': ' to all of these different settings.',\n",
       "   'tokens': [51568, 281, 439, 295, 613, 819, 6257, 13, 51688],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.1197039084001021,\n",
       "   'compression_ratio': 1.8908296943231442,\n",
       "   'no_speech_prob': 0.00260812952183187},\n",
       "  {'id': 46,\n",
       "   'seek': 16640,\n",
       "   'start': 166.48000000000002,\n",
       "   'end': 170.4,\n",
       "   'text': ' So I hope this gives you a sense of the exciting set of problems',\n",
       "   'tokens': [50368,\n",
       "    407,\n",
       "    286,\n",
       "    1454,\n",
       "    341,\n",
       "    2709,\n",
       "    291,\n",
       "    257,\n",
       "    2020,\n",
       "    295,\n",
       "    264,\n",
       "    4670,\n",
       "    992,\n",
       "    295,\n",
       "    2740,\n",
       "    50564],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.17892082275882845,\n",
       "   'compression_ratio': 1.5534591194968554,\n",
       "   'no_speech_prob': 0.0006356158992275596},\n",
       "  {'id': 47,\n",
       "   'seek': 16640,\n",
       "   'start': 170.4,\n",
       "   'end': 173.20000000000002,\n",
       "   'text': ' that sequence models might be that helps you to address.',\n",
       "   'tokens': [50564,\n",
       "    300,\n",
       "    8310,\n",
       "    5245,\n",
       "    1062,\n",
       "    312,\n",
       "    300,\n",
       "    3665,\n",
       "    291,\n",
       "    281,\n",
       "    2985,\n",
       "    13,\n",
       "    50704],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.17892082275882845,\n",
       "   'compression_ratio': 1.5534591194968554,\n",
       "   'no_speech_prob': 0.0006356158992275596},\n",
       "  {'id': 48,\n",
       "   'seek': 16640,\n",
       "   'start': 173.20000000000002,\n",
       "   'end': 175.52,\n",
       "   'text': \" With that, let's go on to the next video,\",\n",
       "   'tokens': [50704,\n",
       "    2022,\n",
       "    300,\n",
       "    11,\n",
       "    718,\n",
       "    311,\n",
       "    352,\n",
       "    322,\n",
       "    281,\n",
       "    264,\n",
       "    958,\n",
       "    960,\n",
       "    11,\n",
       "    50820],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.17892082275882845,\n",
       "   'compression_ratio': 1.5534591194968554,\n",
       "   'no_speech_prob': 0.0006356158992275596},\n",
       "  {'id': 49,\n",
       "   'seek': 16640,\n",
       "   'start': 175.52,\n",
       "   'end': 179.92000000000002,\n",
       "   'text': \" where we start to define the notation we're used to define these sequence problems.\",\n",
       "   'tokens': [50820,\n",
       "    689,\n",
       "    321,\n",
       "    722,\n",
       "    281,\n",
       "    6964,\n",
       "    264,\n",
       "    24657,\n",
       "    321,\n",
       "    434,\n",
       "    1143,\n",
       "    281,\n",
       "    6964,\n",
       "    613,\n",
       "    8310,\n",
       "    2740,\n",
       "    13,\n",
       "    51040],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.17892082275882845,\n",
       "   'compression_ratio': 1.5534591194968554,\n",
       "   'no_speech_prob': 0.0006356158992275596}],\n",
       " 'language': 'en'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
